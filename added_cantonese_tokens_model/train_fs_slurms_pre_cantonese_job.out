args: Namespace(lr=0.0003, model_dir='/scratch/s5600502/thesis_project/mandarin_cantonese/cantonese-tokenized-wav2vec2-model', num_epochs=41, processor_dir='/scratch/s5600502/thesis_project/mandarin_cantonese/cantonese-tokenized-wav2vec2-processor', unfreeze=False, warmup=500)
vocab_size: 3970
lm_head weight shape: torch.Size([3970, 1024])
lm_head bias shape: torch.Size([3970])
Initial model parameters: [Parameter containing:
tensor([ 0.5639,  0.4844, -0.8143,  ...,  0.5477, -0.4740, -0.2588],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[[-0.0298,  0.0603, -0.0827,  ...,  0.1018, -0.0711,  0.0293]],

        [[-0.0607,  0.2050, -0.3389,  ..., -0.2474,  0.1769, -0.0572]],

        [[-0.0755,  0.1939, -0.2712,  ...,  0.1450, -0.0744,  0.0196]],

        ...,

        [[ 0.0910, -0.0274, -0.0011,  ...,  0.2152, -0.2949, -0.1346]],

        [[-0.0821,  0.0699,  0.0469,  ...,  0.0199, -0.0283,  0.0361]],

        [[ 0.0057, -0.0192,  0.0405,  ...,  0.0243,  0.0042, -0.0025]]],
       device='cuda:0'), Parameter containing:
tensor([-0.0116, -0.0229, -0.0242, -0.0107, -0.0113, -0.0121, -0.0220, -0.0385,
        -0.0254, -0.0513, -0.0108, -0.0107, -0.0103, -0.0119, -0.0108, -0.0122,
        -0.0208, -0.0102, -0.0104, -0.0112, -0.0118, -0.0110, -0.0213, -0.0226,
        -0.0014, -0.0104, -0.0121, -0.0108, -0.0118, -0.0470, -0.0111, -0.0124,
        -0.0036, -0.0640, -0.0065, -0.0106, -0.0297, -0.0109, -0.0014, -0.0110,
        -0.0114, -0.0090, -0.0106, -0.0124, -0.0099, -0.0107, -0.0082, -0.0108,
        -0.0662, -0.0144, -0.0384, -0.0116, -0.0457, -0.0111, -0.0424, -0.0106,
        -0.0115, -0.0153, -0.0113, -0.0228, -0.0107, -0.0232, -0.0120, -0.0040,
        -0.0106, -0.0724, -0.0142, -0.0087, -0.0111, -0.0113, -0.0101, -0.0121,
        -0.0107, -0.0110, -0.0725, -0.0414, -0.0013, -0.0098, -0.0100, -0.0108,
        -0.0101, -0.0118, -0.0106, -0.0221, -0.0103, -0.0108, -0.0227, -0.0128,
        -0.0124, -0.0390, -0.0113, -0.0108, -0.0106, -0.0114, -0.0119, -0.0112,
        -0.0107, -0.0124, -0.0132, -0.0112, -0.0109, -0.0387, -0.0111, -0.0109,
        -0.0112, -0.0108, -0.0104, -0.0220, -0.0112, -0.0117, -0.0098, -0.0119,
        -0.0098, -0.0035, -0.0115, -0.0122, -0.0104, -0.0111, -0.0125, -0.0326,
        -0.0238, -0.0132, -0.0060, -0.0126, -0.0109, -0.0094, -0.0101, -0.0132,
        -0.0102, -0.0107, -0.0116, -0.0616, -0.0116, -0.0113, -0.0109, -0.0127,
        -0.0207, -0.0124, -0.0069, -0.0118, -0.0105, -0.0239, -0.0107, -0.0122,
        -0.0118, -0.0105, -0.0109, -0.0129, -0.0118, -0.0234, -0.0111, -0.0103,
        -0.0112, -0.0389, -0.0329, -0.0110, -0.0129, -0.0124, -0.0090, -0.0115,
        -0.0112, -0.0105, -0.0496, -0.0094, -0.0118, -0.0115, -0.0116, -0.0122,
        -0.0111, -0.0056, -0.0146, -0.0112, -0.0108, -0.0081, -0.0735, -0.0111,
        -0.0104, -0.0229, -0.0118, -0.0112, -0.0119, -0.0119, -0.0426, -0.0138,
        -0.0112, -0.0494, -0.0106, -0.0124, -0.0453, -0.0112, -0.0106, -0.0105,
        -0.0122, -0.0110, -0.0250, -0.0112, -0.0440, -0.0596, -0.1772, -0.0113,
        -0.0126, -0.0126, -0.0113, -0.0110, -0.0243, -0.0072, -0.0120, -0.0094,
        -0.0031, -0.0109, -0.0098, -0.0109, -0.0114, -0.0105, -0.0105, -0.0055,
        -0.0137, -0.0111, -0.0365, -0.0110, -0.0099, -0.0241, -0.0130, -0.0125,
        -0.0453, -0.0112, -0.0107, -0.0116, -0.0358, -0.0102, -0.0108, -0.0247,
        -0.0109, -0.0115, -0.0264, -0.0037, -0.0112, -0.0116, -0.0114, -0.0100,
        -0.0118, -0.0157, -0.0101, -0.0642, -0.0103, -0.0100, -0.0121, -0.0117,
        -0.0111, -0.0116, -0.0105, -0.0100, -0.0108, -0.0119, -0.0494, -0.0100,
        -0.0107, -0.0668, -0.0105, -0.0115, -0.0118, -0.0107, -0.0106, -0.0107,
        -0.0115, -0.0553, -0.0109, -0.0575, -0.0112, -0.0120, -0.0118, -0.0334,
        -0.0106, -0.0102, -0.0338, -0.0116, -0.0084, -0.0422, -0.0105, -0.0416,
        -0.0144, -0.0015, -0.0117, -0.0110, -0.0231, -0.0109, -0.0115, -0.0037,
        -0.0110, -0.0028, -0.0103, -0.0125, -0.0585, -0.0106, -0.0464, -0.0105,
        -0.0102, -0.0111, -0.0113, -0.0018,  0.0004, -0.0080, -0.0107, -0.0108,
        -0.0114, -0.0107, -0.0113, -0.0355, -0.0111, -0.0109, -0.0899, -0.0216,
        -0.0114, -0.0517, -0.0125, -0.0108, -0.0114, -0.0118, -0.0147, -0.0994,
        -0.0123, -0.0111, -0.0124, -0.0093, -0.0094, -0.0117, -0.0538, -0.0108,
        -0.0141, -0.0114, -0.0113, -0.0110, -0.0110, -0.0107, -0.0579, -0.0110,
        -0.0453, -0.0139, -0.0430, -0.0452, -0.0123, -0.0091, -0.0121, -0.0110,
        -0.0092, -0.0107, -0.0029, -0.0108, -0.0109, -0.0116, -0.0106, -0.0106,
        -0.0084, -0.0114, -0.0103, -0.0108, -0.0106, -0.0103, -0.0104, -0.0093,
        -0.0110, -0.0115, -0.0116, -0.0774, -0.0120, -0.0109, -0.0121, -0.0306,
        -0.0037, -0.0209, -0.0107, -0.0891, -0.0237, -0.0115, -0.0115, -0.0110,
        -0.0110, -0.0109, -0.0114, -0.0440, -0.0177, -0.0096, -0.0112, -0.0085,
        -0.0387, -0.0108, -0.0100, -0.0454, -0.0446, -0.0099, -0.0254, -0.0264,
        -0.0107, -0.0104, -0.0090, -0.0117, -0.0126, -0.0225, -0.0120, -0.0104,
        -0.0117, -0.0115, -0.0118, -0.0125, -0.0251, -0.0107, -0.0010, -0.0080,
        -0.0071, -0.0107, -0.0103, -0.0684, -0.0050, -0.0111, -0.0324, -0.0112,
        -0.0244, -0.0876, -0.0785, -0.0103, -0.0117, -0.0106, -0.0689, -0.0131,
        -0.0450, -0.0104, -0.0097, -0.0461, -0.0107, -0.0113, -0.0100, -0.0604,
        -0.0099, -0.0117, -0.0013, -0.0099, -0.0970, -0.0093, -0.0101, -0.0109,
        -0.0311, -0.0125, -0.0108, -0.0110, -0.0114, -0.0112, -0.0116, -0.0119,
        -0.0530, -0.0096, -0.0112, -0.0098, -0.0107, -0.0421, -0.0097, -0.0109,
        -0.0097, -0.0095, -0.0106, -0.0047, -0.0180, -0.0410, -0.0106, -0.0102,
        -0.0142, -0.0100, -0.0114, -0.0053, -0.0108, -0.0108, -0.0242, -0.0120,
        -0.0107, -0.0112, -0.0105, -0.0268, -0.0233, -0.0093, -0.0107, -0.0109,
        -0.0096, -0.0102, -0.0123, -0.0105, -0.0102, -0.0109, -0.0110, -0.0119,
        -0.0102, -0.0381, -0.0034, -0.0112, -0.0080, -0.0111, -0.0122, -0.0352,
        -0.0113, -0.0108, -0.0115, -0.0140, -0.0121, -0.0517, -0.0113, -0.0088,
        -0.0112, -0.0109, -0.0109, -0.0106, -0.0060, -0.0015, -0.0124, -0.0122],
       device='cuda:0'), Parameter containing:
tensor([-2.5110e-04,  1.7527e+00,  2.0766e+00,  7.5781e-04,  1.8384e-03,
        -5.6477e-04,  9.8832e-01,  8.2844e-01,  6.7429e-01,  1.1444e+00,
         1.2648e-03,  1.7800e-03, -3.1843e-04,  1.1807e-03,  1.7073e-03,
        -1.2020e-03,  4.3914e-01,  4.4539e-03,  2.6207e-04,  1.1720e-03,
         3.4783e-04,  4.2567e-03,  4.9669e-01,  1.5653e+00,  3.7126e-01,
         1.3646e-03, -7.0154e-05,  3.0722e-03,  1.0361e-02,  1.0621e+00,
         3.1561e-04,  3.6953e-01,  4.3862e-01,  8.9683e-01,  4.0394e-01,
         1.6149e-03,  1.2114e+00,  7.1104e-03,  3.7659e-01,  1.8878e-03,
         5.0378e-03,  1.3543e-03,  3.4644e-03,  9.0145e-04,  3.3629e-04,
         1.9756e-03,  3.1523e-03,  2.8972e-03,  7.7496e-01, -6.3038e-04,
         7.6670e-01,  2.5810e-03,  8.8506e-01,  2.0671e-03,  1.0336e+00,
         8.0139e-03,  5.0223e-04,  4.9354e-01,  9.8842e-04,  1.4354e+00,
         1.4968e-03,  9.9159e-01, -1.5611e-03,  4.0889e-01,  6.4174e-03,
         6.6137e-01,  4.3834e-01,  4.3752e-04,  2.3588e-04,  2.4627e-03,
        -1.8052e-04,  1.7495e-02,  7.6590e-03,  9.8922e-04,  7.6874e-01,
         9.8947e-01,  3.3540e-01,  1.2988e-03,  1.4574e-03,  4.0377e-04,
         1.3093e-03,  1.1668e-03,  2.3945e-03,  1.4944e+00, -2.5192e-04,
         3.8634e-03,  2.7159e+00, -1.2577e-03, -8.2926e-05,  9.8050e-01,
         1.5934e-03,  2.4554e-04,  1.9683e-03, -2.6449e-04,  3.7617e-05,
         1.0764e-02,  8.1284e-03,  1.3045e-04, -7.0605e-06,  1.1993e-02,
         2.0884e-04,  1.1727e+00,  6.8445e-03,  1.0605e-03,  3.1904e-03,
         6.8286e-04,  1.8047e-03,  1.2952e+00,  6.9424e-03,  3.6262e-03,
        -3.3007e-04,  2.3910e-04,  7.9528e-04,  3.4792e-01,  3.5608e-03,
         3.0365e-04,  4.3522e-03,  4.4857e-03, -5.3225e-04,  1.2011e+00,
         1.6405e+00, -6.1168e-04,  4.2782e-01,  4.1323e-05,  8.7505e-03,
         7.3833e-04, -6.5514e-04, -1.3041e-04,  8.5693e-03,  1.0765e-03,
         2.1254e-03,  5.0765e-01, -5.1644e-03,  3.3169e-04,  1.5733e-02,
        -7.5804e-05,  1.4428e+00,  2.5102e-04,  2.9198e-01,  1.1027e-03,
         2.1757e-05,  6.0553e-01,  4.0698e-03,  5.1883e-04, -7.0879e-04,
         6.5975e-04,  8.6139e-04,  9.5790e-05,  3.9926e-05,  7.6030e-01,
         1.4192e-03,  3.8166e-03,  2.7732e-03,  1.0048e+00,  5.2883e-01,
         2.3011e-03,  1.4025e-03, -6.4715e-04,  9.2139e-05,  3.6703e-04,
         1.0531e-02,  1.8632e-03,  8.5522e-01,  2.9855e-01,  4.8807e-04,
         4.4494e-03,  6.7892e-04,  2.4637e-04,  1.9825e-03,  4.2754e-01,
         9.0003e-02,  2.7487e-03, -8.0180e-04,  3.5565e-01,  7.5844e-01,
         5.5128e-03,  9.7886e-03,  1.7398e+00,  1.7908e-03,  2.0332e-03,
         1.7219e-04,  1.1841e-03,  9.3686e-01,  3.7399e-01, -6.2125e-06,
         1.1513e+00,  3.7399e-03,  1.5642e-03,  1.1412e+00,  6.9235e-03,
         6.1081e-04,  1.3888e-03, -8.2742e-04,  3.6064e-03,  9.5979e-01,
        -7.0986e-04,  1.0447e+00,  9.5199e-01,  6.2412e-01,  1.8133e-03,
         1.2452e-03,  2.4949e-01,  6.8426e-04,  5.9600e-03,  1.8201e+00,
         4.9498e-04,  3.3987e-03,  4.2998e-01,  4.1617e-01,  1.2591e-02,
         7.2076e-04,  4.6957e-03, -1.0191e-03,  2.8273e-01,  9.2315e-04,
         2.1083e-01,  2.6021e-01,  6.9881e-03,  1.0229e+00,  5.5826e-03,
        -6.5063e-04,  9.1031e-01,  1.5734e-03,  1.7856e-04,  9.9154e-01,
         7.9992e-03, -1.4565e-04,  2.6201e-03,  8.4612e-01, -1.3961e-04,
         6.5610e-03,  1.4493e+00,  4.2856e-03,  2.4851e-03,  1.4255e+00,
         3.4002e-01,  2.5188e-03,  2.9356e-03,  5.0321e-04,  9.2577e-04,
         1.2196e-04,  3.6970e-01,  8.1470e-04,  7.3140e-01,  3.5383e-03,
         3.8714e-01, -5.2290e-04,  6.5836e-04, -3.8367e-04,  1.6123e-03,
         5.1898e-03,  1.0441e-03,  3.1776e-03, -5.9600e-04,  6.4012e-01,
        -1.3562e-04,  1.4181e-02,  3.3890e-01,  1.8499e-03, -5.4017e-04,
         3.0119e-03,  2.2470e-03,  1.1702e-03,  6.0029e-04,  1.7833e-03,
         9.4151e-01,  9.6592e-03,  1.0382e+00,  1.4516e-03,  1.8966e-03,
         4.5989e-03,  6.1318e-01,  2.0029e-03,  3.3691e-03,  1.1779e+00,
         5.3608e-03,  4.3193e-01,  1.1004e+00,  4.7761e-03,  1.1079e+00,
        -3.8787e-04,  4.0383e-01, -2.9527e-04,  6.7478e-03,  2.1889e+00,
        -2.8231e-04,  3.2895e-04,  4.1436e-01,  3.4090e-03,  3.4491e-01,
        -2.6897e-05,  5.1354e-04,  1.0034e+00,  5.6199e-03,  9.6987e-01,
         1.8298e-04,  9.3597e-04,  1.2500e-02,  2.5576e-03,  4.1666e-01,
         3.4337e-01,  6.2604e-04,  7.2294e-03,  6.1786e-03,  7.7843e-03,
         3.9216e-03,  6.9163e-03,  6.2377e-01,  5.2226e-03,  1.3392e-03,
         5.7949e-01,  1.0405e+00,  7.9567e-04,  1.1027e+00, -4.9815e-04,
         4.4317e-03,  6.4297e-04,  5.2390e-04,  8.8560e-03,  4.6767e-01,
         1.4670e-03,  1.0324e-03,  1.6320e-04,  3.2410e-01, -3.1220e-04,
         5.6114e-03,  1.1517e+00,  2.0380e-02,  5.8916e-03,  6.4236e-04,
         1.9233e-03,  4.5773e-03,  4.5952e-03,  1.5541e-02,  5.1128e-01,
         4.6209e-03,  8.6027e-01,  9.9388e-01,  9.3682e-01,  9.7220e-01,
        -4.7971e-04,  2.7657e-03, -6.1701e-04, -4.8751e-04, -1.5695e-03,
         2.1877e-03,  3.6660e-01,  6.1399e-04,  2.3081e-03,  1.5038e-03,
         3.4122e-01,  1.0765e-03,  5.0282e-03,  2.3856e-03,  1.4172e-03,
         2.6533e-03,  1.3467e-03,  3.3135e-03,  7.4651e-04,  1.4001e-03,
         5.5673e-03, -2.4405e-04,  1.0629e-03,  4.7357e-01,  4.7950e-04,
         1.6585e-02,  4.0680e-04,  5.6789e-01,  3.5734e-01,  1.7969e+00,
         2.1707e-04,  5.9259e-01,  1.8180e+00,  6.8965e-03,  7.1511e-03,
         2.4179e-03,  3.6162e-03,  5.9392e-04,  4.3025e-03,  1.0588e+00,
         4.8011e-01,  6.2412e-04,  1.3033e-03,  1.0776e-03,  9.9185e-01,
         9.5602e-03,  2.9215e-04,  8.6244e-01,  1.1432e+00, -1.9592e-04,
         8.0016e-01,  6.6063e-01,  5.5755e-04,  2.2041e-01,  6.0572e-04,
        -2.8030e-05, -9.2674e-04,  1.8058e+00,  2.3582e-03,  5.3914e-04,
        -1.2320e-04,  3.7099e-04,  2.8658e-03, -3.8419e-04,  7.9401e-01,
         6.5271e-04,  3.0202e-01,  4.2051e-01,  2.8960e-01,  2.3907e-03,
         4.1019e-03,  8.5630e-01,  3.5077e-01,  1.0109e-03,  9.5155e-01,
         7.6544e-04,  8.3189e-01,  7.6712e-01,  7.2212e-01,  4.6768e-03,
         5.2175e-04,  2.7811e-03,  5.4660e-01, -2.3700e-04,  9.2203e-01,
         2.5729e-03,  4.4156e-04,  1.0232e+00,  4.2340e-03,  6.2895e-03,
         3.5710e-03,  9.3379e-01,  4.4525e-04,  3.6331e-04,  3.6095e-01,
        -1.0332e-04,  4.8764e-01,  2.1815e-04,  2.7861e-03,  3.5508e-04,
         1.0687e+00,  3.8221e-01,  9.6083e-04,  1.1022e-02,  3.0859e-03,
         1.5512e-03,  3.8380e-04,  4.6670e-03,  1.2018e+00,  2.0311e-04,
        -5.5991e-04,  3.8941e-04,  5.3606e-03,  9.0738e-01,  7.5075e-01,
         5.9044e-04,  2.5912e-04,  1.7252e-04,  1.5340e-03,  3.4471e-01,
         4.9052e-01,  9.0791e-01,  5.3169e-04,  4.2531e-03,  1.7249e-03,
         2.9765e-04,  7.4316e-04,  3.4061e-01,  6.9193e-04,  1.3372e-02,
         3.3280e-01,  2.4023e-03,  9.0605e-04,  4.0645e-04,  9.7240e-03,
         3.8526e-01,  1.3357e+00, -4.6823e-04,  9.7742e-03, -4.0990e-04,
         2.2518e-03,  1.5671e-03,  8.0947e-04, -2.9876e-05,  1.0530e-03,
         1.0711e-02,  1.8240e-03,  2.7871e-04, -4.5586e-04,  5.8959e-01,
         4.2580e-01, -5.9662e-04,  2.6103e-01,  1.3139e-04,  1.0644e-03,
         1.1368e+00,  3.3132e-03,  6.9060e-03,  5.1012e-03,  1.1119e-03,
        -2.3784e-04,  9.1430e-01,  5.4119e-03,  3.7752e-05,  8.1496e-03,
         6.2590e-05,  1.4297e-03,  2.3570e-03,  3.5034e-01,  2.6404e-01,
         3.9576e-04,  1.1366e-03], device='cuda:0'), Parameter containing:
tensor([ 3.6945e-05,  6.4860e-01,  8.1515e-01, -2.3699e-05, -9.0310e-05,
         6.4266e-05,  3.0391e-01, -8.8835e-01,  3.6522e-01, -5.7207e-01,
        -3.3894e-05, -1.7132e-04, -6.4498e-04, -6.5930e-04, -1.2554e-04,
        -3.9221e-04, -5.9715e-03, -1.7101e-03, -2.3347e-04, -2.2071e-04,
        -9.7375e-04, -9.4273e-05,  1.3640e-01,  5.4589e-01, -3.1952e-01,
         8.4512e-04, -3.9401e-04, -1.0459e-04, -2.6340e-03, -1.2299e+00,
         1.6775e-04, -1.6117e-01, -3.1808e-01,  5.2391e-01, -2.3148e-01,
        -8.1666e-04, -1.0966e+00, -1.8704e-03, -3.2386e-01, -7.0517e-05,
        -1.5411e-03, -8.2864e-05, -7.9673e-04, -3.7526e-04,  1.1217e-04,
        -7.2391e-04, -1.8280e-03, -4.6746e-04,  6.2864e-01,  1.7329e-04,
        -1.2410e+00, -4.6088e-04, -1.0959e+00, -7.1738e-04, -1.1698e+00,
        -1.4775e-03,  2.8582e-04, -8.3449e-02, -3.2993e-04, -1.0578e+00,
        -2.6515e-04,  3.1094e-01, -5.2077e-04, -2.9232e-01, -1.0545e-03,
         1.0509e-01, -8.5113e-02, -2.9610e-04, -4.3698e-04, -5.3959e-04,
        -6.4720e-04, -3.6690e-03, -1.3107e-03, -2.6719e-04,  7.1034e-02,
        -1.0323e+00, -3.1671e-01, -3.7172e-04, -3.9998e-05, -4.6599e-04,
        -4.5333e-04, -5.3549e-04, -5.6554e-04,  3.0647e-01, -2.5297e-04,
        -1.0333e-03,  9.5112e-01,  1.4902e-05,  6.1819e-04, -8.3347e-01,
        -3.1676e-04, -1.1802e-03, -1.1966e-03, -5.0883e-04,  9.8211e-04,
        -2.7392e-03, -1.9787e-03, -1.7489e-04, -3.9031e-04, -3.7434e-03,
         4.1956e-04, -7.8401e-01, -1.9505e-03,  1.6094e-04, -7.5723e-04,
        -5.3220e-04,  8.4798e-05,  3.5112e-01, -1.4923e-03, -5.3820e-04,
         2.9218e-04,  2.4810e-04,  1.1313e-04, -2.4983e-01, -9.2545e-04,
         4.1947e-04, -5.8690e-04, -9.9914e-04,  7.9848e-04, -1.0487e+00,
         6.0578e-01, -2.4619e-04, -2.8280e-01,  5.1275e-05, -2.7126e-03,
         5.4492e-05,  6.9927e-05,  7.6986e-04, -2.0469e-03, -4.9376e-04,
        -3.5391e-04,  4.2808e-01,  2.4217e-03, -3.1249e-04, -4.3160e-03,
        -4.8007e-04,  2.9585e-01,  1.2011e-03, -1.8556e-01, -5.1521e-04,
        -1.0598e-03,  3.9195e-01, -1.8578e-03, -4.0392e-05,  3.5599e-04,
        -1.1778e-04, -5.1736e-04,  1.5766e-04, -4.0000e-04, -1.1546e+00,
        -3.3656e-04, -3.6162e-04, -1.0132e-03, -9.5163e-01,  4.7658e-01,
        -1.3134e-04, -6.0519e-05,  5.5556e-04, -4.2458e-04,  2.3324e-04,
        -2.5537e-03,  1.4163e-04, -6.3163e-01, -1.5432e-01,  9.3084e-05,
        -4.5303e-04, -5.0295e-04, -1.0119e-04, -8.9987e-04, -2.9208e-01,
        -1.1792e-02,  1.6038e-04, -1.4462e-03, -2.3590e-01, -2.3146e-01,
        -7.0114e-04, -2.4416e-03,  6.5888e-01,  6.7286e-04,  1.3843e-04,
         2.9837e-05,  8.3680e-04, -1.2420e+00, -9.9050e-02, -4.8077e-04,
        -4.9825e-01, -1.1929e-03,  1.0625e-03, -1.0179e+00, -2.2100e-03,
        -1.6977e-04, -4.3941e-04, -1.5894e-04, -1.6464e-03,  3.9546e-01,
        -1.2140e-03, -1.1224e+00,  3.5846e-02,  4.7103e-01,  7.8756e-04,
         3.7229e-04, -6.2792e-02,  1.1832e-04, -8.3853e-04,  4.1920e-01,
         3.8665e-04, -2.3847e-04, -2.3733e-01, -3.3695e-01, -3.6813e-03,
         7.4589e-04, -1.2997e-03, -8.6146e-04, -1.4158e-01,  9.6202e-05,
        -1.4176e-01, -4.2643e-02, -1.0431e-03, -9.8521e-01, -2.4365e-03,
        -6.0886e-05,  3.1282e-01, -4.8715e-06, -7.0538e-04, -1.0129e+00,
        -2.4179e-03, -5.5108e-04,  9.7542e-04, -1.2119e+00, -4.0067e-05,
        -2.3515e-03, -1.2294e+00, -1.4435e-03,  1.9071e-04,  6.0666e-01,
        -2.7540e-01,  7.8393e-05, -3.1169e-04, -3.6302e-04, -4.8117e-04,
         8.1739e-04, -3.7979e-02,  7.7587e-04,  5.5172e-01, -6.3641e-04,
        -1.8864e-01,  1.1213e-03, -1.9541e-04, -2.2684e-04, -1.0427e-03,
        -2.0549e-03,  4.6800e-04, -1.8861e-03, -8.5080e-04, -1.3481e+00,
        -1.7402e-04, -3.5104e-03,  2.1282e-01,  6.3948e-05,  6.0016e-05,
        -4.9504e-04, -3.2872e-05, -9.4852e-05,  7.2773e-05,  5.4202e-04,
        -6.0553e-01, -1.5965e-03, -2.8798e-01,  7.3185e-04, -9.5458e-04,
        -3.3732e-04,  5.8940e-01, -8.4221e-04, -1.3036e-03, -1.1702e+00,
        -6.1636e-04, -2.5438e-01, -1.1605e+00, -2.3391e-03, -8.9651e-01,
         4.5393e-04, -3.5123e-01,  2.6379e-04, -2.1784e-03,  7.8387e-01,
        -1.6080e-04,  2.9816e-04, -3.6688e-01, -8.6565e-04, -2.4564e-01,
        -2.0180e-04,  1.0960e-04,  2.7685e-02, -1.0325e-03, -7.6786e-01,
        -7.4016e-04, -3.5774e-04, -2.6337e-03, -5.5443e-04, -3.8826e-01,
        -3.1187e-01, -6.0094e-04, -2.0936e-03, -1.3544e-03, -1.6453e-03,
        -1.1313e-03, -9.1895e-04,  5.5286e-01, -1.2066e-03,  5.5376e-05,
         3.0904e-01,  2.6346e-01, -6.6303e-04, -4.2804e-01, -4.3460e-04,
        -7.5775e-04, -1.7700e-03, -6.7580e-04,  1.5801e-03,  3.4014e-01,
        -6.5040e-04, -9.3519e-04, -8.6254e-05, -1.5169e-01, -5.4616e-04,
        -9.2946e-04, -2.5245e-01, -4.5810e-03, -4.7382e-04, -1.2332e-04,
         7.1458e-04,  3.3253e-05, -1.0810e-03, -6.4372e-03,  4.2580e-02,
        -3.9932e-04, -8.9996e-01, -1.1113e+00, -1.1646e+00, -1.1142e+00,
        -2.0813e-04, -2.4020e-04, -8.2422e-04, -1.0074e-03, -1.0084e-03,
         1.6721e-04, -2.9474e-01, -1.0623e-04,  6.7033e-04,  6.7725e-04,
        -1.3386e-01,  1.5354e-04, -9.2517e-04, -5.6823e-04, -3.9400e-04,
        -3.7679e-04, -9.7338e-04,  1.3798e-04, -7.3170e-06, -1.6553e-04,
        -4.7253e-04, -1.4306e-03, -1.2046e-03,  5.9360e-01, -1.0298e-04,
        -3.9614e-03, -8.7242e-04,  3.7938e-01, -3.0182e-01,  3.2051e-01,
        -6.7481e-04,  3.2592e-01,  5.0041e-01, -2.0200e-03, -2.8809e-04,
         2.3068e-04, -3.9498e-04,  2.4530e-04, -9.4930e-04, -7.3282e-01,
        -1.0387e-01,  3.8680e-04,  7.1401e-04, -4.4025e-04, -1.0420e+00,
        -1.7750e-03, -1.7367e-05, -1.2432e+00, -8.6676e-01, -2.2003e-04,
        -1.1277e+00,  3.7944e-01,  6.1314e-04, -8.8214e-02,  9.7271e-04,
        -5.3237e-04, -3.5063e-04,  6.6102e-01, -1.5945e-04,  1.1285e-04,
        -1.6915e-04,  3.3331e-04, -6.9348e-04,  3.9317e-04,  3.4068e-01,
         4.7580e-04, -2.3277e-01, -2.3731e-01, -1.6389e-01, -1.0358e-03,
        -1.2850e-03,  2.8795e-01, -2.3579e-01,  1.4818e-04, -1.0999e+00,
        -1.3672e-04,  3.4113e-01,  4.2621e-01,  5.7805e-02, -8.8626e-04,
        -3.4432e-04, -7.5623e-04,  3.9553e-01, -1.2598e-04, -1.3171e+00,
        -9.7989e-04,  2.5643e-04, -1.2510e+00, -1.5879e-03, -1.1577e-03,
        -1.0218e-03, -6.6212e-01, -7.5012e-04,  2.8385e-04, -2.7960e-01,
         2.4840e-04,  3.3092e-01,  7.3799e-05, -4.5616e-04,  5.4196e-04,
        -1.3464e+00, -1.5763e-01,  1.5463e-04, -2.5353e-03, -1.4605e-04,
        -5.6782e-04,  1.3687e-04, -8.5836e-04, -6.5349e-01,  7.8517e-04,
        -6.1249e-04, -8.6619e-04, -7.5329e-04, -1.2680e+00, -6.9321e-01,
        -8.6539e-04,  2.6452e-04,  7.1301e-04,  2.2386e-04, -2.2180e-01,
         1.5876e-01, -1.3325e+00, -2.7806e-04, -8.3646e-04, -7.4513e-05,
        -3.8763e-04, -2.4255e-04, -1.8079e-01,  1.2209e-04, -3.6474e-03,
         1.2028e-01,  8.7612e-04,  3.5534e-04, -8.9509e-05, -2.8592e-03,
         2.2651e-01,  4.9974e-01, -3.8632e-04, -2.3511e-03,  2.4507e-04,
        -1.4766e-03,  5.6831e-04,  8.7394e-04, -3.0700e-04, -7.1349e-04,
        -1.1394e-03, -6.0909e-04,  3.1060e-04, -2.0727e-04, -1.1788e+00,
        -3.6970e-01,  3.2112e-04, -1.5255e-01,  9.1926e-04, -2.3487e-04,
        -9.7316e-01, -5.4825e-04, -2.3405e-03, -5.7774e-04,  5.0926e-04,
         1.0597e-03, -5.8870e-01, -1.1358e-03, -1.2324e-03, -1.6600e-03,
        -6.4162e-04,  2.1405e-04,  1.8266e-04, -2.2990e-01, -2.1036e-01,
         8.0976e-04, -8.8189e-05], device='cuda:0')]
{'loss': 4.1534, 'learning_rate': 0.00029320157468783447, 'epoch': 1.0}
Epoch 1.0: Training Loss: 4.1534
{'eval_loss': 2.00761342048645, 'eval_cer': 0.49386020151133503, 'eval_runtime': 26.2192, 'eval_samples_per_second': 21.32, 'eval_steps_per_second': 2.67, 'epoch': 1.0}
Epoch 1.0: Validation Loss: 2.0076

Epoch 1.0: Validation CER: 0.4939
Best model saved with CER: 0.4939 at epoch 1
{'loss': 2.1159, 'learning_rate': 0.00028587488275270495, 'epoch': 2.0}
Epoch 2.0: Training Loss: 2.1159
{'eval_loss': 1.7671979665756226, 'eval_cer': 0.4288413098236776, 'eval_runtime': 25.2544, 'eval_samples_per_second': 22.135, 'eval_steps_per_second': 2.772, 'epoch': 2.0}
Epoch 2.0: Validation Loss: 1.7672

Epoch 2.0: Validation CER: 0.4288
Best model saved with CER: 0.4288 at epoch 2
{'loss': 1.7531, 'learning_rate': 0.0002785471447450547, 'epoch': 3.0}
Epoch 3.0: Training Loss: 1.7531
{'eval_loss': 1.5950508117675781, 'eval_cer': 0.5765113350125944, 'eval_runtime': 26.6165, 'eval_samples_per_second': 21.002, 'eval_steps_per_second': 2.63, 'epoch': 3.0}
Epoch 3.0: Validation Loss: 1.5951

Epoch 3.0: Validation CER: 0.5765
{'loss': 1.512, 'learning_rate': 0.0002712194067374044, 'epoch': 4.0}
Epoch 4.0: Training Loss: 1.5120
{'eval_loss': 1.517909049987793, 'eval_cer': 0.33753148614609574, 'eval_runtime': 24.883, 'eval_samples_per_second': 22.465, 'eval_steps_per_second': 2.813, 'epoch': 4.0}
Epoch 4.0: Validation Loss: 1.5179

Epoch 4.0: Validation CER: 0.3375
Best model saved with CER: 0.3375 at epoch 4
{'loss': 1.3354, 'learning_rate': 0.00026389376087479553, 'epoch': 5.0}
Epoch 5.0: Training Loss: 1.3354
{'eval_loss': 1.5001779794692993, 'eval_cer': 0.35532115869017633, 'eval_runtime': 25.0345, 'eval_samples_per_second': 22.329, 'eval_steps_per_second': 2.796, 'epoch': 5.0}
Epoch 5.0: Validation Loss: 1.5002

Epoch 5.0: Validation CER: 0.3553
{'loss': 1.1892, 'learning_rate': 0.000256567068939666, 'epoch': 6.0}
Epoch 6.0: Training Loss: 1.1892
{'eval_loss': 1.389126181602478, 'eval_cer': 0.3214735516372796, 'eval_runtime': 25.0992, 'eval_samples_per_second': 22.272, 'eval_steps_per_second': 2.789, 'epoch': 6.0}
Epoch 6.0: Validation Loss: 1.3891

Epoch 6.0: Validation CER: 0.3215
Best model saved with CER: 0.3215 at epoch 6
{'loss': 1.0681, 'learning_rate': 0.00024924037700453644, 'epoch': 7.0}
Epoch 7.0: Training Loss: 1.0681
{'eval_loss': 1.4449793100357056, 'eval_cer': 0.3214735516372796, 'eval_runtime': 25.053, 'eval_samples_per_second': 22.313, 'eval_steps_per_second': 2.794, 'epoch': 7.0}
Epoch 7.0: Validation Loss: 1.4450

Epoch 7.0: Validation CER: 0.3215
{'loss': 0.9746, 'learning_rate': 0.00024191263899688616, 'epoch': 8.0}
Epoch 8.0: Training Loss: 0.9746
{'eval_loss': 1.460680365562439, 'eval_cer': 0.2989609571788413, 'eval_runtime': 25.3841, 'eval_samples_per_second': 22.022, 'eval_steps_per_second': 2.758, 'epoch': 8.0}
Epoch 8.0: Validation Loss: 1.4607

Epoch 8.0: Validation CER: 0.2990
Best model saved with CER: 0.2990 at epoch 8
{'loss': 0.8684, 'learning_rate': 0.00023458594706175662, 'epoch': 9.0}
Epoch 9.0: Training Loss: 0.8684
{'eval_loss': 1.4285534620285034, 'eval_cer': 0.2970717884130982, 'eval_runtime': 25.7817, 'eval_samples_per_second': 21.682, 'eval_steps_per_second': 2.715, 'epoch': 9.0}
Epoch 9.0: Validation Loss: 1.4286

Epoch 9.0: Validation CER: 0.2971
Best model saved with CER: 0.2971 at epoch 9
{'loss': 0.778, 'learning_rate': 0.00022725820905410634, 'epoch': 10.0}
Epoch 10.0: Training Loss: 0.7780
{'eval_loss': 1.480461597442627, 'eval_cer': 0.2945528967254408, 'eval_runtime': 25.2119, 'eval_samples_per_second': 22.172, 'eval_steps_per_second': 2.776, 'epoch': 10.0}
Epoch 10.0: Validation Loss: 1.4805

Epoch 10.0: Validation CER: 0.2946
Best model saved with CER: 0.2946 at epoch 10
{'loss': 0.703, 'learning_rate': 0.0002199315171189768, 'epoch': 11.0}
Epoch 11.0: Training Loss: 0.7030
{'eval_loss': 1.5332576036453247, 'eval_cer': 0.3123425692695214, 'eval_runtime': 25.4012, 'eval_samples_per_second': 22.007, 'eval_steps_per_second': 2.756, 'epoch': 11.0}
Epoch 11.0: Validation Loss: 1.5333

Epoch 11.0: Validation CER: 0.3123
{'loss': 0.6456, 'learning_rate': 0.00021260482518384722, 'epoch': 12.0}
Epoch 12.0: Training Loss: 0.6456
{'eval_loss': 1.450721263885498, 'eval_cer': 0.288727959697733, 'eval_runtime': 25.1465, 'eval_samples_per_second': 22.23, 'eval_steps_per_second': 2.784, 'epoch': 12.0}
Epoch 12.0: Validation Loss: 1.4507

Epoch 12.0: Validation CER: 0.2887
Best model saved with CER: 0.2887 at epoch 12
{'loss': 0.5924, 'learning_rate': 0.00020527708717619697, 'epoch': 13.0}
Epoch 13.0: Training Loss: 0.5924
{'eval_loss': 1.4763822555541992, 'eval_cer': 0.27802267002518893, 'eval_runtime': 25.0874, 'eval_samples_per_second': 22.282, 'eval_steps_per_second': 2.79, 'epoch': 13.0}
Epoch 13.0: Validation Loss: 1.4764

Epoch 13.0: Validation CER: 0.2780
Best model saved with CER: 0.2780 at epoch 13
{'loss': 0.5324, 'learning_rate': 0.0001979503952410674, 'epoch': 14.0}
Epoch 14.0: Training Loss: 0.5324
{'eval_loss': 1.446805715560913, 'eval_cer': 0.27093828715365237, 'eval_runtime': 25.1446, 'eval_samples_per_second': 22.231, 'eval_steps_per_second': 2.784, 'epoch': 14.0}
Epoch 14.0: Validation Loss: 1.4468

Epoch 14.0: Validation CER: 0.2709
Best model saved with CER: 0.2709 at epoch 14
{'loss': 0.4923, 'learning_rate': 0.00019062370330593786, 'epoch': 15.0}
Epoch 15.0: Training Loss: 0.4923
{'eval_loss': 1.4534603357315063, 'eval_cer': 0.2755037783375315, 'eval_runtime': 25.864, 'eval_samples_per_second': 21.613, 'eval_steps_per_second': 2.706, 'epoch': 15.0}
Epoch 15.0: Validation Loss: 1.4535

Epoch 15.0: Validation CER: 0.2755
{'loss': 0.4677, 'learning_rate': 0.00018329596529828755, 'epoch': 16.0}
Epoch 16.0: Training Loss: 0.4677
{'eval_loss': 1.4745941162109375, 'eval_cer': 0.26102015113350124, 'eval_runtime': 24.8607, 'eval_samples_per_second': 22.485, 'eval_steps_per_second': 2.816, 'epoch': 16.0}
Epoch 16.0: Validation Loss: 1.4746

Epoch 16.0: Validation CER: 0.2610
Best model saved with CER: 0.2610 at epoch 16
{'loss': 0.4249, 'learning_rate': 0.0001759682272906373, 'epoch': 17.0}
Epoch 17.0: Training Loss: 0.4249
{'eval_loss': 1.5178947448730469, 'eval_cer': 0.26574307304785894, 'eval_runtime': 26.2545, 'eval_samples_per_second': 21.292, 'eval_steps_per_second': 2.666, 'epoch': 17.0}
Epoch 17.0: Validation Loss: 1.5179

Epoch 17.0: Validation CER: 0.2657
{'loss': 0.3913, 'learning_rate': 0.00016864048928298702, 'epoch': 18.0}
Epoch 18.0: Training Loss: 0.3913
{'eval_loss': 1.5498366355895996, 'eval_cer': 0.2660579345088161, 'eval_runtime': 26.7307, 'eval_samples_per_second': 20.912, 'eval_steps_per_second': 2.619, 'epoch': 18.0}
Epoch 18.0: Validation Loss: 1.5498

Epoch 18.0: Validation CER: 0.2661
{'loss': 0.36, 'learning_rate': 0.00016131379734785748, 'epoch': 19.0}
Epoch 19.0: Training Loss: 0.3600
{'eval_loss': 1.4827767610549927, 'eval_cer': 0.25566750629722923, 'eval_runtime': 25.7969, 'eval_samples_per_second': 21.669, 'eval_steps_per_second': 2.714, 'epoch': 19.0}
Epoch 19.0: Validation Loss: 1.4828

Epoch 19.0: Validation CER: 0.2557
Best model saved with CER: 0.2557 at epoch 19
{'loss': 0.3465, 'learning_rate': 0.0001539871054127279, 'epoch': 20.0}
Epoch 20.0: Training Loss: 0.3465
{'eval_loss': 1.5045974254608154, 'eval_cer': 0.24874055415617127, 'eval_runtime': 26.0189, 'eval_samples_per_second': 21.484, 'eval_steps_per_second': 2.69, 'epoch': 20.0}
Epoch 20.0: Validation Loss: 1.5046

Epoch 20.0: Validation CER: 0.2487
Best model saved with CER: 0.2487 at epoch 20
{'loss': 0.3241, 'learning_rate': 0.00014666041347759836, 'epoch': 21.0}
Epoch 21.0: Training Loss: 0.3241
{'eval_loss': 1.522957682609558, 'eval_cer': 0.2531486146095718, 'eval_runtime': 25.7714, 'eval_samples_per_second': 21.691, 'eval_steps_per_second': 2.716, 'epoch': 21.0}
Epoch 21.0: Validation Loss: 1.5230

Epoch 21.0: Validation CER: 0.2531
{'loss': 0.2967, 'learning_rate': 0.0001393337215424688, 'epoch': 22.0}
Epoch 22.0: Training Loss: 0.2967
{'eval_loss': 1.5828595161437988, 'eval_cer': 0.258816120906801, 'eval_runtime': 25.4612, 'eval_samples_per_second': 21.955, 'eval_steps_per_second': 2.749, 'epoch': 22.0}
Epoch 22.0: Validation Loss: 1.5829

Epoch 22.0: Validation CER: 0.2588
{'loss': 0.2806, 'learning_rate': 0.0001320059835348185, 'epoch': 23.0}
Epoch 23.0: Training Loss: 0.2806
{'eval_loss': 1.532541036605835, 'eval_cer': 0.24669395465994962, 'eval_runtime': 26.3857, 'eval_samples_per_second': 21.186, 'eval_steps_per_second': 2.653, 'epoch': 23.0}
Epoch 23.0: Validation Loss: 1.5325

Epoch 23.0: Validation CER: 0.2467
Best model saved with CER: 0.2467 at epoch 23
{'loss': 0.2634, 'learning_rate': 0.00012467929159968897, 'epoch': 24.0}
Epoch 24.0: Training Loss: 0.2634
{'eval_loss': 1.5510542392730713, 'eval_cer': 0.24653652392947104, 'eval_runtime': 24.899, 'eval_samples_per_second': 22.451, 'eval_steps_per_second': 2.811, 'epoch': 24.0}
Epoch 24.0: Validation Loss: 1.5511

Epoch 24.0: Validation CER: 0.2465
Best model saved with CER: 0.2465 at epoch 24
{'loss': 0.2381, 'learning_rate': 0.00011735155359203869, 'epoch': 25.0}
Epoch 25.0: Training Loss: 0.2381
{'eval_loss': 1.5433483123779297, 'eval_cer': 0.24716624685138538, 'eval_runtime': 25.2297, 'eval_samples_per_second': 22.156, 'eval_steps_per_second': 2.775, 'epoch': 25.0}
Epoch 25.0: Validation Loss: 1.5433

Epoch 25.0: Validation CER: 0.2472
{'loss': 0.2183, 'learning_rate': 0.00011002381558438841, 'epoch': 26.0}
Epoch 26.0: Training Loss: 0.2183
{'eval_loss': 1.5542267560958862, 'eval_cer': 0.2396095717884131, 'eval_runtime': 25.4488, 'eval_samples_per_second': 21.966, 'eval_steps_per_second': 2.751, 'epoch': 26.0}
Epoch 26.0: Validation Loss: 1.5542

Epoch 26.0: Validation CER: 0.2396
Best model saved with CER: 0.2396 at epoch 26
{'loss': 0.2079, 'learning_rate': 0.00010269712364925885, 'epoch': 27.0}
Epoch 27.0: Training Loss: 0.2079
{'eval_loss': 1.5355923175811768, 'eval_cer': 0.23016372795969772, 'eval_runtime': 25.3003, 'eval_samples_per_second': 22.095, 'eval_steps_per_second': 2.767, 'epoch': 27.0}
Epoch 27.0: Validation Loss: 1.5356

Epoch 27.0: Validation CER: 0.2302
Best model saved with CER: 0.2302 at epoch 27
{'loss': 0.1973, 'learning_rate': 9.536938564160857e-05, 'epoch': 28.0}
Epoch 28.0: Training Loss: 0.1973
{'eval_loss': 1.5481820106506348, 'eval_cer': 0.24291561712846346, 'eval_runtime': 25.954, 'eval_samples_per_second': 21.538, 'eval_steps_per_second': 2.697, 'epoch': 28.0}
Epoch 28.0: Validation Loss: 1.5482

Epoch 28.0: Validation CER: 0.2429
{'loss': 0.1857, 'learning_rate': 8.804269370647901e-05, 'epoch': 29.0}
Epoch 29.0: Training Loss: 0.1857
{'eval_loss': 1.499712586402893, 'eval_cer': 0.22953400503778337, 'eval_runtime': 24.9218, 'eval_samples_per_second': 22.43, 'eval_steps_per_second': 2.809, 'epoch': 29.0}
Epoch 29.0: Validation Loss: 1.4997

Epoch 29.0: Validation CER: 0.2295
Best model saved with CER: 0.2295 at epoch 29
{'loss': 0.1766, 'learning_rate': 8.071600177134946e-05, 'epoch': 30.0}
Epoch 30.0: Training Loss: 0.1766
{'eval_loss': 1.513244390487671, 'eval_cer': 0.22843198992443325, 'eval_runtime': 24.878, 'eval_samples_per_second': 22.47, 'eval_steps_per_second': 2.814, 'epoch': 30.0}
Epoch 30.0: Validation Loss: 1.5132

Epoch 30.0: Validation CER: 0.2284
Best model saved with CER: 0.2284 at epoch 30
{'loss': 0.1647, 'learning_rate': 7.33893098362199e-05, 'epoch': 31.0}
Epoch 31.0: Training Loss: 0.1647
{'eval_loss': 1.485066533088684, 'eval_cer': 0.23173803526448364, 'eval_runtime': 24.8043, 'eval_samples_per_second': 22.536, 'eval_steps_per_second': 2.822, 'epoch': 31.0}
Epoch 31.0: Validation Loss: 1.4851

Epoch 31.0: Validation CER: 0.2317
{'loss': 0.1515, 'learning_rate': 6.606157182856963e-05, 'epoch': 32.0}
Epoch 32.0: Training Loss: 0.1515
{'eval_loss': 1.4519462585449219, 'eval_cer': 0.22811712846347607, 'eval_runtime': 25.1553, 'eval_samples_per_second': 22.222, 'eval_steps_per_second': 2.783, 'epoch': 32.0}
Epoch 32.0: Validation Loss: 1.4519

Epoch 32.0: Validation CER: 0.2281
Best model saved with CER: 0.2281 at epoch 32
{'loss': 0.1346, 'learning_rate': 5.873383382091935e-05, 'epoch': 33.0}
Epoch 33.0: Training Loss: 0.1346
{'eval_loss': 1.484422206878662, 'eval_cer': 0.22811712846347607, 'eval_runtime': 24.8325, 'eval_samples_per_second': 22.511, 'eval_steps_per_second': 2.819, 'epoch': 33.0}
Epoch 33.0: Validation Loss: 1.4844

Epoch 33.0: Validation CER: 0.2281
{'loss': 0.1301, 'learning_rate': 5.1407141885789804e-05, 'epoch': 34.0}
Epoch 34.0: Training Loss: 0.1301
{'eval_loss': 1.4630383253097534, 'eval_cer': 0.22355163727959698, 'eval_runtime': 25.2561, 'eval_samples_per_second': 22.133, 'eval_steps_per_second': 2.772, 'epoch': 34.0}
Epoch 34.0: Validation Loss: 1.4630

Epoch 34.0: Validation CER: 0.2236
Best model saved with CER: 0.2236 at epoch 34
{'loss': 0.1241, 'learning_rate': 4.407940387813952e-05, 'epoch': 35.0}
Epoch 35.0: Training Loss: 0.1241
{'eval_loss': 1.433026909828186, 'eval_cer': 0.2260705289672544, 'eval_runtime': 25.4295, 'eval_samples_per_second': 21.982, 'eval_steps_per_second': 2.753, 'epoch': 35.0}
Epoch 35.0: Validation Loss: 1.4330

Epoch 35.0: Validation CER: 0.2261
{'loss': 0.1162, 'learning_rate': 3.675271194300997e-05, 'epoch': 36.0}
Epoch 36.0: Training Loss: 0.1162
{'eval_loss': 1.4294030666351318, 'eval_cer': 0.2232367758186398, 'eval_runtime': 25.0494, 'eval_samples_per_second': 22.316, 'eval_steps_per_second': 2.794, 'epoch': 36.0}
Epoch 36.0: Validation Loss: 1.4294

Epoch 36.0: Validation CER: 0.2232
Best model saved with CER: 0.2232 at epoch 36
{'loss': 0.1063, 'learning_rate': 2.942602000788041e-05, 'epoch': 37.0}
Epoch 37.0: Training Loss: 0.1063
{'eval_loss': 1.4503473043441772, 'eval_cer': 0.21945843828715364, 'eval_runtime': 24.6296, 'eval_samples_per_second': 22.696, 'eval_steps_per_second': 2.842, 'epoch': 37.0}
Epoch 37.0: Validation Loss: 1.4503

Epoch 37.0: Validation CER: 0.2195
Best model saved with CER: 0.2195 at epoch 37
{'loss': 0.1016, 'learning_rate': 2.2099328072750854e-05, 'epoch': 38.0}
Epoch 38.0: Training Loss: 0.1016
{'eval_loss': 1.4146816730499268, 'eval_cer': 0.22229219143576825, 'eval_runtime': 25.6113, 'eval_samples_per_second': 21.826, 'eval_steps_per_second': 2.733, 'epoch': 38.0}
Epoch 38.0: Validation Loss: 1.4147

Epoch 38.0: Validation CER: 0.2223
{'loss': 0.0928, 'learning_rate': 1.477368221014202e-05, 'epoch': 39.0}
Epoch 39.0: Training Loss: 0.0928
{'eval_loss': 1.4370208978652954, 'eval_cer': 0.21819899244332494, 'eval_runtime': 25.2467, 'eval_samples_per_second': 22.141, 'eval_steps_per_second': 2.773, 'epoch': 39.0}
Epoch 39.0: Validation Loss: 1.4370

Epoch 39.0: Validation CER: 0.2182
Best model saved with CER: 0.2182 at epoch 39
{'loss': 0.0908, 'learning_rate': 7.445944202491744e-06, 'epoch': 40.0}
Epoch 40.0: Training Loss: 0.0908
{'eval_loss': 1.4040569067001343, 'eval_cer': 0.21709697732997482, 'eval_runtime': 25.201, 'eval_samples_per_second': 22.182, 'eval_steps_per_second': 2.778, 'epoch': 40.0}
Epoch 40.0: Validation Loss: 1.4041

Epoch 40.0: Validation CER: 0.2171
Best model saved with CER: 0.2171 at epoch 40
{'loss': 0.0857, 'learning_rate': 1.1925226736218865e-07, 'epoch': 41.0}
Epoch 41.0: Training Loss: 0.0857
{'eval_loss': 1.3880693912506104, 'eval_cer': 0.21646725440806044, 'eval_runtime': 25.7953, 'eval_samples_per_second': 21.671, 'eval_steps_per_second': 2.714, 'epoch': 41.0}
Epoch 41.0: Validation Loss: 1.3881

Epoch 41.0: Validation CER: 0.2165
Best model saved with CER: 0.2165 at epoch 41
{'train_runtime': 131227.7703, 'train_samples_per_second': 4.378, 'train_steps_per_second': 2.189, 'train_loss': 0.5949104381130357, 'epoch': 41.0}
Final model parameters: [Parameter containing:
tensor([ 0.6668,  0.2588, -0.8456,  ...,  0.6346, -0.6330, -0.4450],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[[-0.0298,  0.0603, -0.0827,  ...,  0.1018, -0.0711,  0.0293]],

        [[-0.0607,  0.2050, -0.3389,  ..., -0.2474,  0.1769, -0.0572]],

        [[-0.0755,  0.1939, -0.2712,  ...,  0.1450, -0.0744,  0.0196]],

        ...,

        [[ 0.0910, -0.0274, -0.0011,  ...,  0.2152, -0.2949, -0.1346]],

        [[-0.0821,  0.0699,  0.0469,  ...,  0.0199, -0.0283,  0.0361]],

        [[ 0.0057, -0.0192,  0.0405,  ...,  0.0243,  0.0042, -0.0025]]],
       device='cuda:0'), Parameter containing:
tensor([-0.0116, -0.0229, -0.0242, -0.0107, -0.0113, -0.0121, -0.0220, -0.0385,
        -0.0254, -0.0513, -0.0108, -0.0107, -0.0103, -0.0119, -0.0108, -0.0122,
        -0.0208, -0.0102, -0.0104, -0.0112, -0.0118, -0.0110, -0.0213, -0.0226,
        -0.0014, -0.0104, -0.0121, -0.0108, -0.0118, -0.0470, -0.0111, -0.0124,
        -0.0036, -0.0640, -0.0065, -0.0106, -0.0297, -0.0109, -0.0014, -0.0110,
        -0.0114, -0.0090, -0.0106, -0.0124, -0.0099, -0.0107, -0.0082, -0.0108,
        -0.0662, -0.0144, -0.0384, -0.0116, -0.0457, -0.0111, -0.0424, -0.0106,
        -0.0115, -0.0153, -0.0113, -0.0228, -0.0107, -0.0232, -0.0120, -0.0040,
        -0.0106, -0.0724, -0.0142, -0.0087, -0.0111, -0.0113, -0.0101, -0.0121,
        -0.0107, -0.0110, -0.0725, -0.0414, -0.0013, -0.0098, -0.0100, -0.0108,
        -0.0101, -0.0118, -0.0106, -0.0221, -0.0103, -0.0108, -0.0227, -0.0128,
        -0.0124, -0.0390, -0.0113, -0.0108, -0.0106, -0.0114, -0.0119, -0.0112,
        -0.0107, -0.0124, -0.0132, -0.0112, -0.0109, -0.0387, -0.0111, -0.0109,
        -0.0112, -0.0108, -0.0104, -0.0220, -0.0112, -0.0117, -0.0098, -0.0119,
        -0.0098, -0.0035, -0.0115, -0.0122, -0.0104, -0.0111, -0.0125, -0.0326,
        -0.0238, -0.0132, -0.0060, -0.0126, -0.0109, -0.0094, -0.0101, -0.0132,
        -0.0102, -0.0107, -0.0116, -0.0616, -0.0116, -0.0113, -0.0109, -0.0127,
        -0.0207, -0.0124, -0.0069, -0.0118, -0.0105, -0.0239, -0.0107, -0.0122,
        -0.0118, -0.0105, -0.0109, -0.0129, -0.0118, -0.0234, -0.0111, -0.0103,
        -0.0112, -0.0389, -0.0329, -0.0110, -0.0129, -0.0124, -0.0090, -0.0115,
        -0.0112, -0.0105, -0.0496, -0.0094, -0.0118, -0.0115, -0.0116, -0.0122,
        -0.0111, -0.0056, -0.0146, -0.0112, -0.0108, -0.0081, -0.0735, -0.0111,
        -0.0104, -0.0229, -0.0118, -0.0112, -0.0119, -0.0119, -0.0426, -0.0138,
        -0.0112, -0.0494, -0.0106, -0.0124, -0.0453, -0.0112, -0.0106, -0.0105,
        -0.0122, -0.0110, -0.0250, -0.0112, -0.0440, -0.0596, -0.1772, -0.0113,
        -0.0126, -0.0126, -0.0113, -0.0110, -0.0243, -0.0072, -0.0120, -0.0094,
        -0.0031, -0.0109, -0.0098, -0.0109, -0.0114, -0.0105, -0.0105, -0.0055,
        -0.0137, -0.0111, -0.0365, -0.0110, -0.0099, -0.0241, -0.0130, -0.0125,
        -0.0453, -0.0112, -0.0107, -0.0116, -0.0358, -0.0102, -0.0108, -0.0247,
        -0.0109, -0.0115, -0.0264, -0.0037, -0.0112, -0.0116, -0.0114, -0.0100,
        -0.0118, -0.0157, -0.0101, -0.0642, -0.0103, -0.0100, -0.0121, -0.0117,
        -0.0111, -0.0116, -0.0105, -0.0100, -0.0108, -0.0119, -0.0494, -0.0100,
        -0.0107, -0.0668, -0.0105, -0.0115, -0.0118, -0.0107, -0.0106, -0.0107,
        -0.0115, -0.0553, -0.0109, -0.0575, -0.0112, -0.0120, -0.0118, -0.0334,
        -0.0106, -0.0102, -0.0338, -0.0116, -0.0084, -0.0422, -0.0105, -0.0416,
        -0.0144, -0.0015, -0.0117, -0.0110, -0.0231, -0.0109, -0.0115, -0.0037,
        -0.0110, -0.0028, -0.0103, -0.0125, -0.0585, -0.0106, -0.0464, -0.0105,
        -0.0102, -0.0111, -0.0113, -0.0018,  0.0004, -0.0080, -0.0107, -0.0108,
        -0.0114, -0.0107, -0.0113, -0.0355, -0.0111, -0.0109, -0.0899, -0.0216,
        -0.0114, -0.0517, -0.0125, -0.0108, -0.0114, -0.0118, -0.0147, -0.0994,
        -0.0123, -0.0111, -0.0124, -0.0093, -0.0094, -0.0117, -0.0538, -0.0108,
        -0.0141, -0.0114, -0.0113, -0.0110, -0.0110, -0.0107, -0.0579, -0.0110,
        -0.0453, -0.0139, -0.0430, -0.0452, -0.0123, -0.0091, -0.0121, -0.0110,
        -0.0092, -0.0107, -0.0029, -0.0108, -0.0109, -0.0116, -0.0106, -0.0106,
        -0.0084, -0.0114, -0.0103, -0.0108, -0.0106, -0.0103, -0.0104, -0.0093,
        -0.0110, -0.0115, -0.0116, -0.0774, -0.0120, -0.0109, -0.0121, -0.0306,
        -0.0037, -0.0209, -0.0107, -0.0891, -0.0237, -0.0115, -0.0115, -0.0110,
        -0.0110, -0.0109, -0.0114, -0.0440, -0.0177, -0.0096, -0.0112, -0.0085,
        -0.0387, -0.0108, -0.0100, -0.0454, -0.0446, -0.0099, -0.0254, -0.0264,
        -0.0107, -0.0104, -0.0090, -0.0117, -0.0126, -0.0225, -0.0120, -0.0104,
        -0.0117, -0.0115, -0.0118, -0.0125, -0.0251, -0.0107, -0.0010, -0.0080,
        -0.0071, -0.0107, -0.0103, -0.0684, -0.0050, -0.0111, -0.0324, -0.0112,
        -0.0244, -0.0876, -0.0785, -0.0103, -0.0117, -0.0106, -0.0689, -0.0131,
        -0.0450, -0.0104, -0.0097, -0.0461, -0.0107, -0.0113, -0.0100, -0.0604,
        -0.0099, -0.0117, -0.0013, -0.0099, -0.0970, -0.0093, -0.0101, -0.0109,
        -0.0311, -0.0125, -0.0108, -0.0110, -0.0114, -0.0112, -0.0116, -0.0119,
        -0.0530, -0.0096, -0.0112, -0.0098, -0.0107, -0.0421, -0.0097, -0.0109,
        -0.0097, -0.0095, -0.0106, -0.0047, -0.0180, -0.0410, -0.0106, -0.0102,
        -0.0142, -0.0100, -0.0114, -0.0053, -0.0108, -0.0108, -0.0242, -0.0120,
        -0.0107, -0.0112, -0.0105, -0.0268, -0.0233, -0.0093, -0.0107, -0.0109,
        -0.0096, -0.0102, -0.0123, -0.0105, -0.0102, -0.0109, -0.0110, -0.0119,
        -0.0102, -0.0381, -0.0034, -0.0112, -0.0080, -0.0111, -0.0122, -0.0352,
        -0.0113, -0.0108, -0.0115, -0.0140, -0.0121, -0.0517, -0.0113, -0.0088,
        -0.0112, -0.0109, -0.0109, -0.0106, -0.0060, -0.0015, -0.0124, -0.0122],
       device='cuda:0'), Parameter containing:
tensor([-2.5110e-04,  1.7527e+00,  2.0766e+00,  7.5781e-04,  1.8384e-03,
        -5.6477e-04,  9.8832e-01,  8.2844e-01,  6.7429e-01,  1.1444e+00,
         1.2648e-03,  1.7800e-03, -3.1843e-04,  1.1807e-03,  1.7073e-03,
        -1.2020e-03,  4.3914e-01,  4.4539e-03,  2.6207e-04,  1.1720e-03,
         3.4783e-04,  4.2567e-03,  4.9669e-01,  1.5653e+00,  3.7126e-01,
         1.3646e-03, -7.0154e-05,  3.0722e-03,  1.0361e-02,  1.0621e+00,
         3.1561e-04,  3.6953e-01,  4.3862e-01,  8.9683e-01,  4.0394e-01,
         1.6149e-03,  1.2114e+00,  7.1104e-03,  3.7659e-01,  1.8878e-03,
         5.0378e-03,  1.3543e-03,  3.4644e-03,  9.0145e-04,  3.3629e-04,
         1.9756e-03,  3.1523e-03,  2.8972e-03,  7.7496e-01, -6.3038e-04,
         7.6670e-01,  2.5810e-03,  8.8506e-01,  2.0671e-03,  1.0336e+00,
         8.0139e-03,  5.0223e-04,  4.9354e-01,  9.8842e-04,  1.4354e+00,
         1.4968e-03,  9.9159e-01, -1.5611e-03,  4.0889e-01,  6.4174e-03,
         6.6137e-01,  4.3834e-01,  4.3752e-04,  2.3588e-04,  2.4627e-03,
        -1.8052e-04,  1.7495e-02,  7.6590e-03,  9.8922e-04,  7.6874e-01,
         9.8947e-01,  3.3540e-01,  1.2988e-03,  1.4574e-03,  4.0377e-04,
         1.3093e-03,  1.1668e-03,  2.3945e-03,  1.4944e+00, -2.5192e-04,
         3.8634e-03,  2.7159e+00, -1.2577e-03, -8.2926e-05,  9.8050e-01,
         1.5934e-03,  2.4554e-04,  1.9683e-03, -2.6449e-04,  3.7617e-05,
         1.0764e-02,  8.1284e-03,  1.3045e-04, -7.0605e-06,  1.1993e-02,
         2.0884e-04,  1.1727e+00,  6.8445e-03,  1.0605e-03,  3.1904e-03,
         6.8286e-04,  1.8047e-03,  1.2952e+00,  6.9424e-03,  3.6262e-03,
        -3.3007e-04,  2.3910e-04,  7.9528e-04,  3.4792e-01,  3.5608e-03,
         3.0365e-04,  4.3522e-03,  4.4857e-03, -5.3225e-04,  1.2011e+00,
         1.6405e+00, -6.1168e-04,  4.2782e-01,  4.1323e-05,  8.7505e-03,
         7.3833e-04, -6.5514e-04, -1.3041e-04,  8.5693e-03,  1.0765e-03,
         2.1254e-03,  5.0765e-01, -5.1644e-03,  3.3169e-04,  1.5733e-02,
        -7.5804e-05,  1.4428e+00,  2.5102e-04,  2.9198e-01,  1.1027e-03,
         2.1757e-05,  6.0553e-01,  4.0698e-03,  5.1883e-04, -7.0879e-04,
         6.5975e-04,  8.6139e-04,  9.5790e-05,  3.9926e-05,  7.6030e-01,
         1.4192e-03,  3.8166e-03,  2.7732e-03,  1.0048e+00,  5.2883e-01,
         2.3011e-03,  1.4025e-03, -6.4715e-04,  9.2139e-05,  3.6703e-04,
         1.0531e-02,  1.8632e-03,  8.5522e-01,  2.9855e-01,  4.8807e-04,
         4.4494e-03,  6.7892e-04,  2.4637e-04,  1.9825e-03,  4.2754e-01,
         9.0003e-02,  2.7487e-03, -8.0180e-04,  3.5565e-01,  7.5844e-01,
         5.5128e-03,  9.7886e-03,  1.7398e+00,  1.7908e-03,  2.0332e-03,
         1.7219e-04,  1.1841e-03,  9.3686e-01,  3.7399e-01, -6.2125e-06,
         1.1513e+00,  3.7399e-03,  1.5642e-03,  1.1412e+00,  6.9235e-03,
         6.1081e-04,  1.3888e-03, -8.2742e-04,  3.6064e-03,  9.5979e-01,
        -7.0986e-04,  1.0447e+00,  9.5199e-01,  6.2412e-01,  1.8133e-03,
         1.2452e-03,  2.4949e-01,  6.8426e-04,  5.9600e-03,  1.8201e+00,
         4.9498e-04,  3.3987e-03,  4.2998e-01,  4.1617e-01,  1.2591e-02,
         7.2076e-04,  4.6957e-03, -1.0191e-03,  2.8273e-01,  9.2315e-04,
         2.1083e-01,  2.6021e-01,  6.9881e-03,  1.0229e+00,  5.5826e-03,
        -6.5063e-04,  9.1031e-01,  1.5734e-03,  1.7856e-04,  9.9154e-01,
         7.9992e-03, -1.4565e-04,  2.6201e-03,  8.4612e-01, -1.3961e-04,
         6.5610e-03,  1.4493e+00,  4.2856e-03,  2.4851e-03,  1.4255e+00,
         3.4002e-01,  2.5188e-03,  2.9356e-03,  5.0321e-04,  9.2577e-04,
         1.2196e-04,  3.6970e-01,  8.1470e-04,  7.3140e-01,  3.5383e-03,
         3.8714e-01, -5.2290e-04,  6.5836e-04, -3.8367e-04,  1.6123e-03,
         5.1898e-03,  1.0441e-03,  3.1776e-03, -5.9600e-04,  6.4012e-01,
        -1.3562e-04,  1.4181e-02,  3.3890e-01,  1.8499e-03, -5.4017e-04,
         3.0119e-03,  2.2470e-03,  1.1702e-03,  6.0029e-04,  1.7833e-03,
         9.4151e-01,  9.6592e-03,  1.0382e+00,  1.4516e-03,  1.8966e-03,
         4.5989e-03,  6.1318e-01,  2.0029e-03,  3.3691e-03,  1.1779e+00,
         5.3608e-03,  4.3193e-01,  1.1004e+00,  4.7761e-03,  1.1079e+00,
        -3.8787e-04,  4.0383e-01, -2.9527e-04,  6.7478e-03,  2.1889e+00,
        -2.8231e-04,  3.2895e-04,  4.1436e-01,  3.4090e-03,  3.4491e-01,
        -2.6897e-05,  5.1354e-04,  1.0034e+00,  5.6199e-03,  9.6987e-01,
         1.8298e-04,  9.3597e-04,  1.2500e-02,  2.5576e-03,  4.1666e-01,
         3.4337e-01,  6.2604e-04,  7.2294e-03,  6.1786e-03,  7.7843e-03,
         3.9216e-03,  6.9163e-03,  6.2377e-01,  5.2226e-03,  1.3392e-03,
         5.7949e-01,  1.0405e+00,  7.9567e-04,  1.1027e+00, -4.9815e-04,
         4.4317e-03,  6.4297e-04,  5.2390e-04,  8.8560e-03,  4.6767e-01,
         1.4670e-03,  1.0324e-03,  1.6320e-04,  3.2410e-01, -3.1220e-04,
         5.6114e-03,  1.1517e+00,  2.0380e-02,  5.8916e-03,  6.4236e-04,
         1.9233e-03,  4.5773e-03,  4.5952e-03,  1.5541e-02,  5.1128e-01,
         4.6209e-03,  8.6027e-01,  9.9388e-01,  9.3682e-01,  9.7220e-01,
        -4.7971e-04,  2.7657e-03, -6.1701e-04, -4.8751e-04, -1.5695e-03,
         2.1877e-03,  3.6660e-01,  6.1399e-04,  2.3081e-03,  1.5038e-03,
         3.4122e-01,  1.0765e-03,  5.0282e-03,  2.3856e-03,  1.4172e-03,
         2.6533e-03,  1.3467e-03,  3.3135e-03,  7.4651e-04,  1.4001e-03,
         5.5673e-03, -2.4405e-04,  1.0629e-03,  4.7357e-01,  4.7950e-04,
         1.6585e-02,  4.0680e-04,  5.6789e-01,  3.5734e-01,  1.7969e+00,
         2.1707e-04,  5.9259e-01,  1.8180e+00,  6.8965e-03,  7.1511e-03,
         2.4179e-03,  3.6162e-03,  5.9392e-04,  4.3025e-03,  1.0588e+00,
         4.8011e-01,  6.2412e-04,  1.3033e-03,  1.0776e-03,  9.9185e-01,
         9.5602e-03,  2.9215e-04,  8.6244e-01,  1.1432e+00, -1.9592e-04,
         8.0016e-01,  6.6063e-01,  5.5755e-04,  2.2041e-01,  6.0572e-04,
        -2.8030e-05, -9.2674e-04,  1.8058e+00,  2.3582e-03,  5.3914e-04,
        -1.2320e-04,  3.7099e-04,  2.8658e-03, -3.8419e-04,  7.9401e-01,
         6.5271e-04,  3.0202e-01,  4.2051e-01,  2.8960e-01,  2.3907e-03,
         4.1019e-03,  8.5630e-01,  3.5077e-01,  1.0109e-03,  9.5155e-01,
         7.6544e-04,  8.3189e-01,  7.6712e-01,  7.2212e-01,  4.6768e-03,
         5.2175e-04,  2.7811e-03,  5.4660e-01, -2.3700e-04,  9.2203e-01,
         2.5729e-03,  4.4156e-04,  1.0232e+00,  4.2340e-03,  6.2895e-03,
         3.5710e-03,  9.3379e-01,  4.4525e-04,  3.6331e-04,  3.6095e-01,
        -1.0332e-04,  4.8764e-01,  2.1815e-04,  2.7861e-03,  3.5508e-04,
         1.0687e+00,  3.8221e-01,  9.6083e-04,  1.1022e-02,  3.0859e-03,
         1.5512e-03,  3.8380e-04,  4.6670e-03,  1.2018e+00,  2.0311e-04,
        -5.5991e-04,  3.8941e-04,  5.3606e-03,  9.0738e-01,  7.5075e-01,
         5.9044e-04,  2.5912e-04,  1.7252e-04,  1.5340e-03,  3.4471e-01,
         4.9052e-01,  9.0791e-01,  5.3169e-04,  4.2531e-03,  1.7249e-03,
         2.9765e-04,  7.4316e-04,  3.4061e-01,  6.9193e-04,  1.3372e-02,
         3.3280e-01,  2.4023e-03,  9.0605e-04,  4.0645e-04,  9.7240e-03,
         3.8526e-01,  1.3357e+00, -4.6823e-04,  9.7742e-03, -4.0990e-04,
         2.2518e-03,  1.5671e-03,  8.0947e-04, -2.9876e-05,  1.0530e-03,
         1.0711e-02,  1.8240e-03,  2.7871e-04, -4.5586e-04,  5.8959e-01,
         4.2580e-01, -5.9662e-04,  2.6103e-01,  1.3139e-04,  1.0644e-03,
         1.1368e+00,  3.3132e-03,  6.9060e-03,  5.1012e-03,  1.1119e-03,
        -2.3784e-04,  9.1430e-01,  5.4119e-03,  3.7752e-05,  8.1496e-03,
         6.2590e-05,  1.4297e-03,  2.3570e-03,  3.5034e-01,  2.6404e-01,
         3.9576e-04,  1.1366e-03], device='cuda:0'), Parameter containing:
tensor([ 3.6945e-05,  6.4860e-01,  8.1515e-01, -2.3699e-05, -9.0310e-05,
         6.4266e-05,  3.0391e-01, -8.8835e-01,  3.6522e-01, -5.7207e-01,
        -3.3894e-05, -1.7132e-04, -6.4498e-04, -6.5930e-04, -1.2554e-04,
        -3.9221e-04, -5.9715e-03, -1.7101e-03, -2.3347e-04, -2.2071e-04,
        -9.7375e-04, -9.4273e-05,  1.3640e-01,  5.4589e-01, -3.1952e-01,
         8.4512e-04, -3.9401e-04, -1.0459e-04, -2.6340e-03, -1.2299e+00,
         1.6775e-04, -1.6117e-01, -3.1808e-01,  5.2391e-01, -2.3148e-01,
        -8.1666e-04, -1.0966e+00, -1.8704e-03, -3.2386e-01, -7.0517e-05,
        -1.5411e-03, -8.2864e-05, -7.9673e-04, -3.7526e-04,  1.1217e-04,
        -7.2391e-04, -1.8280e-03, -4.6746e-04,  6.2864e-01,  1.7329e-04,
        -1.2410e+00, -4.6088e-04, -1.0959e+00, -7.1738e-04, -1.1698e+00,
        -1.4775e-03,  2.8582e-04, -8.3449e-02, -3.2993e-04, -1.0578e+00,
        -2.6515e-04,  3.1094e-01, -5.2077e-04, -2.9232e-01, -1.0545e-03,
         1.0509e-01, -8.5113e-02, -2.9610e-04, -4.3698e-04, -5.3959e-04,
        -6.4720e-04, -3.6690e-03, -1.3107e-03, -2.6719e-04,  7.1034e-02,
        -1.0323e+00, -3.1671e-01, -3.7172e-04, -3.9998e-05, -4.6599e-04,
        -4.5333e-04, -5.3549e-04, -5.6554e-04,  3.0647e-01, -2.5297e-04,
        -1.0333e-03,  9.5112e-01,  1.4902e-05,  6.1819e-04, -8.3347e-01,
        -3.1676e-04, -1.1802e-03, -1.1966e-03, -5.0883e-04,  9.8211e-04,
        -2.7392e-03, -1.9787e-03, -1.7489e-04, -3.9031e-04, -3.7434e-03,
         4.1956e-04, -7.8401e-01, -1.9505e-03,  1.6094e-04, -7.5723e-04,
        -5.3220e-04,  8.4798e-05,  3.5112e-01, -1.4923e-03, -5.3820e-04,
         2.9218e-04,  2.4810e-04,  1.1313e-04, -2.4983e-01, -9.2545e-04,
         4.1947e-04, -5.8690e-04, -9.9914e-04,  7.9848e-04, -1.0487e+00,
         6.0578e-01, -2.4619e-04, -2.8280e-01,  5.1275e-05, -2.7126e-03,
         5.4492e-05,  6.9927e-05,  7.6986e-04, -2.0469e-03, -4.9376e-04,
        -3.5391e-04,  4.2808e-01,  2.4217e-03, -3.1249e-04, -4.3160e-03,
        -4.8007e-04,  2.9585e-01,  1.2011e-03, -1.8556e-01, -5.1521e-04,
        -1.0598e-03,  3.9195e-01, -1.8578e-03, -4.0392e-05,  3.5599e-04,
        -1.1778e-04, -5.1736e-04,  1.5766e-04, -4.0000e-04, -1.1546e+00,
        -3.3656e-04, -3.6162e-04, -1.0132e-03, -9.5163e-01,  4.7658e-01,
        -1.3134e-04, -6.0519e-05,  5.5556e-04, -4.2458e-04,  2.3324e-04,
        -2.5537e-03,  1.4163e-04, -6.3163e-01, -1.5432e-01,  9.3084e-05,
        -4.5303e-04, -5.0295e-04, -1.0119e-04, -8.9987e-04, -2.9208e-01,
        -1.1792e-02,  1.6038e-04, -1.4462e-03, -2.3590e-01, -2.3146e-01,
        -7.0114e-04, -2.4416e-03,  6.5888e-01,  6.7286e-04,  1.3843e-04,
         2.9837e-05,  8.3680e-04, -1.2420e+00, -9.9050e-02, -4.8077e-04,
        -4.9825e-01, -1.1929e-03,  1.0625e-03, -1.0179e+00, -2.2100e-03,
        -1.6977e-04, -4.3941e-04, -1.5894e-04, -1.6464e-03,  3.9546e-01,
        -1.2140e-03, -1.1224e+00,  3.5846e-02,  4.7103e-01,  7.8756e-04,
         3.7229e-04, -6.2792e-02,  1.1832e-04, -8.3853e-04,  4.1920e-01,
         3.8665e-04, -2.3847e-04, -2.3733e-01, -3.3695e-01, -3.6813e-03,
         7.4589e-04, -1.2997e-03, -8.6146e-04, -1.4158e-01,  9.6202e-05,
        -1.4176e-01, -4.2643e-02, -1.0431e-03, -9.8521e-01, -2.4365e-03,
        -6.0886e-05,  3.1282e-01, -4.8715e-06, -7.0538e-04, -1.0129e+00,
        -2.4179e-03, -5.5108e-04,  9.7542e-04, -1.2119e+00, -4.0067e-05,
        -2.3515e-03, -1.2294e+00, -1.4435e-03,  1.9071e-04,  6.0666e-01,
        -2.7540e-01,  7.8393e-05, -3.1169e-04, -3.6302e-04, -4.8117e-04,
         8.1739e-04, -3.7979e-02,  7.7587e-04,  5.5172e-01, -6.3641e-04,
        -1.8864e-01,  1.1213e-03, -1.9541e-04, -2.2684e-04, -1.0427e-03,
        -2.0549e-03,  4.6800e-04, -1.8861e-03, -8.5080e-04, -1.3481e+00,
        -1.7402e-04, -3.5104e-03,  2.1282e-01,  6.3948e-05,  6.0016e-05,
        -4.9504e-04, -3.2872e-05, -9.4852e-05,  7.2773e-05,  5.4202e-04,
        -6.0553e-01, -1.5965e-03, -2.8798e-01,  7.3185e-04, -9.5458e-04,
        -3.3732e-04,  5.8940e-01, -8.4221e-04, -1.3036e-03, -1.1702e+00,
        -6.1636e-04, -2.5438e-01, -1.1605e+00, -2.3391e-03, -8.9651e-01,
         4.5393e-04, -3.5123e-01,  2.6379e-04, -2.1784e-03,  7.8387e-01,
        -1.6080e-04,  2.9816e-04, -3.6688e-01, -8.6565e-04, -2.4564e-01,
        -2.0180e-04,  1.0960e-04,  2.7685e-02, -1.0325e-03, -7.6786e-01,
        -7.4016e-04, -3.5774e-04, -2.6337e-03, -5.5443e-04, -3.8826e-01,
        -3.1187e-01, -6.0094e-04, -2.0936e-03, -1.3544e-03, -1.6453e-03,
        -1.1313e-03, -9.1895e-04,  5.5286e-01, -1.2066e-03,  5.5376e-05,
         3.0904e-01,  2.6346e-01, -6.6303e-04, -4.2804e-01, -4.3460e-04,
        -7.5775e-04, -1.7700e-03, -6.7580e-04,  1.5801e-03,  3.4014e-01,
        -6.5040e-04, -9.3519e-04, -8.6254e-05, -1.5169e-01, -5.4616e-04,
        -9.2946e-04, -2.5245e-01, -4.5810e-03, -4.7382e-04, -1.2332e-04,
         7.1458e-04,  3.3253e-05, -1.0810e-03, -6.4372e-03,  4.2580e-02,
        -3.9932e-04, -8.9996e-01, -1.1113e+00, -1.1646e+00, -1.1142e+00,
        -2.0813e-04, -2.4020e-04, -8.2422e-04, -1.0074e-03, -1.0084e-03,
         1.6721e-04, -2.9474e-01, -1.0623e-04,  6.7033e-04,  6.7725e-04,
        -1.3386e-01,  1.5354e-04, -9.2517e-04, -5.6823e-04, -3.9400e-04,
        -3.7679e-04, -9.7338e-04,  1.3798e-04, -7.3170e-06, -1.6553e-04,
        -4.7253e-04, -1.4306e-03, -1.2046e-03,  5.9360e-01, -1.0298e-04,
        -3.9614e-03, -8.7242e-04,  3.7938e-01, -3.0182e-01,  3.2051e-01,
        -6.7481e-04,  3.2592e-01,  5.0041e-01, -2.0200e-03, -2.8809e-04,
         2.3068e-04, -3.9498e-04,  2.4530e-04, -9.4930e-04, -7.3282e-01,
        -1.0387e-01,  3.8680e-04,  7.1401e-04, -4.4025e-04, -1.0420e+00,
        -1.7750e-03, -1.7367e-05, -1.2432e+00, -8.6676e-01, -2.2003e-04,
        -1.1277e+00,  3.7944e-01,  6.1314e-04, -8.8214e-02,  9.7271e-04,
        -5.3237e-04, -3.5063e-04,  6.6102e-01, -1.5945e-04,  1.1285e-04,
        -1.6915e-04,  3.3331e-04, -6.9348e-04,  3.9317e-04,  3.4068e-01,
         4.7580e-04, -2.3277e-01, -2.3731e-01, -1.6389e-01, -1.0358e-03,
        -1.2850e-03,  2.8795e-01, -2.3579e-01,  1.4818e-04, -1.0999e+00,
        -1.3672e-04,  3.4113e-01,  4.2621e-01,  5.7805e-02, -8.8626e-04,
        -3.4432e-04, -7.5623e-04,  3.9553e-01, -1.2598e-04, -1.3171e+00,
        -9.7989e-04,  2.5643e-04, -1.2510e+00, -1.5879e-03, -1.1577e-03,
        -1.0218e-03, -6.6212e-01, -7.5012e-04,  2.8385e-04, -2.7960e-01,
         2.4840e-04,  3.3092e-01,  7.3799e-05, -4.5616e-04,  5.4196e-04,
        -1.3464e+00, -1.5763e-01,  1.5463e-04, -2.5353e-03, -1.4605e-04,
        -5.6782e-04,  1.3687e-04, -8.5836e-04, -6.5349e-01,  7.8517e-04,
        -6.1249e-04, -8.6619e-04, -7.5329e-04, -1.2680e+00, -6.9321e-01,
        -8.6539e-04,  2.6452e-04,  7.1301e-04,  2.2386e-04, -2.2180e-01,
         1.5876e-01, -1.3325e+00, -2.7806e-04, -8.3646e-04, -7.4513e-05,
        -3.8763e-04, -2.4255e-04, -1.8079e-01,  1.2209e-04, -3.6474e-03,
         1.2028e-01,  8.7612e-04,  3.5534e-04, -8.9509e-05, -2.8592e-03,
         2.2651e-01,  4.9974e-01, -3.8632e-04, -2.3511e-03,  2.4507e-04,
        -1.4766e-03,  5.6831e-04,  8.7394e-04, -3.0700e-04, -7.1349e-04,
        -1.1394e-03, -6.0909e-04,  3.1060e-04, -2.0727e-04, -1.1788e+00,
        -3.6970e-01,  3.2112e-04, -1.5255e-01,  9.1926e-04, -2.3487e-04,
        -9.7316e-01, -5.4825e-04, -2.3405e-03, -5.7774e-04,  5.0926e-04,
         1.0597e-03, -5.8870e-01, -1.1358e-03, -1.2324e-03, -1.6600e-03,
        -6.4162e-04,  2.1405e-04,  1.8266e-04, -2.2990e-01, -2.1036e-01,
         8.0976e-04, -8.8189e-05], device='cuda:0')]

###############################################################################
Hábrók Cluster
Job 10509515 for user s5600502
Finished at: Fri Jun 21 16:40:57 CEST 2024

Job details:
============

Job ID                         : 10509515
Name                           : train_fs_slurm_pre_cantonese_job
User                           : s5600502
Partition                      : gpulong
Nodes                          : v100gpu6
Number of Nodes                : 1
Cores                          : 8
Number of Tasks                : 1
State                          : RUNNING  
Submit                         : 2024-06-20T03:14:44
Start                          : 2024-06-20T03:55:48
End                            : --
Reserved walltime              : 2-00:00:00
Used walltime                  : 1-12:45:09
Used CPU time                  : -- 
% User (Computation)           : --
% System (I/O)                 : --
Total memory reserved          : 64G
Maximum memory used            : --
Requested GPUs                 : v100=1
Allocated GPUs                 : v100=1
Max GPU utilization            : --
Max GPU memory used            : --

Acknowledgements:
=================

Please see this page for information about acknowledging Hábrók in your publications:

https://wiki.hpc.rug.nl/habrok/introduction/scientific_output

################################################################################
